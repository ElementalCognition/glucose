GLUCOSE is a largescale database for common sense reasoning collected via crowd sourcing. 

This resource is available under [license]
Please cite [ACL citation] when using this corpus.

This download contains an approximately 223MB csv file with 71,979 rows and 54 columns.   

There are 337,636 rules filled in, each being a mini-theory with both a specific statment of the mini-theory and a general statement of the mini-theory

Each rule is described by a quality rating, which is based on the worker's performance on the row of responses. We assume about 10% errors on the rating numbers. 
All the data, regardless of quality rating, were collected from workers who passed challenging qualification tasks and were subsequently trained for improved quality on the task.
For details on how the ratings were created and determined, see [link to data quality management document]. 

The quality ratings are:
3 = Highest quality. Rules display an accurate level of generalization in the general rules. Rules make sense and are appropriate for the sentence, given the context. 
2 = Mid-quality raing. These are still very good rules that have a good balance of generality, but a higher percetage in this set may be overly specific, use attribute clauses less proficiently, or not be as conceptually concise
3 = Lower-quality rating. These rules are still useable, but a higher percentage of them have, in addition to the issues in the 2-level ratings, highly specific general rules and some misunderstanding of how to use attribute clauses. 

The data in the csv has 54 columns. The data in the columns is described below. The column label is given, along with its index, the the header for that column, a description of the column contents, and example of what occurs in the column, and an example of how the data can be used. Optionally, there is then a "NOTE" if there is anything unexpected in the data format.

A(0); header: unique_id; description: a randomly generated alphanumeric sequence for a given story with the sentence index appended at the end after two underscores; example: cbee2b5a-f2f9-4bca-9630-6825b1e36c13__0; uses: find all user responses to a particular sentence in a given story
B(1); header: story_id; description: a randomly generated alphanumeric sequence to uniquely identify a story; example: cbee2b5a-f2f9-4bca-9630-6825b1e36c13__0; uses: find all data for a particular story
C(2); header: selected_sentence_index; description: the index of a given sentence in a story; example: 0; uses: how users respond to the first sentence versus the last, which index of a story contains the most conceptual information (all ROC stories are the same length)
D(3); header: worker_id; [CONTENT REMOVED FOR WORKER PRIVACY]
E(3); header: worker_quality_assessment; description: rating for the worker on the assignment in the row; example: 2; uses: divide data by work quality
F(4); header: assignment_id; description: a unique alphanumeric identifier generated by AWS Mturk to index the combination of a worker on a given HIT; example: 3OF2M9AATHFS2H1426Q5C1JUT9EKZJ uses: find a particular response by this unique identifier
G(5); header: submission_time; description: the date and time of worker submission; example: 2019-10-05T16:44:16.000Z ; uses: sort submissions by date
H(6); header: duration; description: how long a worker worked on a HIT. Minutes are before the decimal, seconds after; example: 9.85 ; uses: determine averages of how long workers took to complete HITs.; NOTES: It is a known issue that some durations come back as large negative numbers. It is also the case that some workers accept a HIT and then do not start working on it for some large amount of time. For this reason, when determining average worker time, it is best to exclude negative numbers and numbers over a certain threshold (for example, over 30 mintes) 
I(7); header: assignment_status; description: provides the status of the assignment, usually Approved, but occassionally Rejected; example: Approved; uses: can sort on Approved, Submitted, Rejected status.; NOTE: Data labeled as "Rejected" can be excluded, but is OK to keep.
J(8); header: story; description: contains the full text of the ROC story that was used for the HIT. Each sentence is separated by "***"; example: The school football game was last weekend.****The team has been very good this year.****They have won a lot of games.****A lot of people showed up to watch.****They won by a ton of points.; uses: stories can be used to filter based on vocabulary or topics
K(9)-AX(50); header: 1_specificNL - 10_generalStructured; description: For each of the ten dimensions, there are four columns. The columns occur in this order "n_specificNL, n_specificStructured, n_generalNL, n_generalStructured", where n is in 1-10. The specific columns give the specific statements from the story. The general statements give the corresponding generalization. The NL columns are formated in natural language, whereas the structured columns contain indications of the slots used to fill in the data.; example: The school  has  a football team  >Causes/Enables> The football game  was last weekend 	{The school }_[subject] {has }_[verb] {a football team }_[object1] >Causes/Enables> {The football game }_[subject] {was last weekend }_[verb]	Somewhere_A (that is a school ) has  Something_A (that is a sports team ) >Causes/Enables> The game  was last weekend 	{Somewhere_A ||that is a school ||}_[subject] {has }_[verb] {Something_A ||that is a sports team ||}_[object1] >Causes/Enables> {The game }_[subject] {was last weekend }_[verb]; uses: This is the primary data collected. It provides the common sense knowledge about the related stories and those general rules about the world derived from the specific statements
AY(51); header: number_filled_in; description: the number of dimensions that the worker filled in. Each set of general and specific, structured and unstructured, counts as one.; example: 3; uses: averaging how many dimensions workers supplied
AZ(52); header: submission_time_normalized; formating of the submission time in YYYYMMDD format; example: 20191005; uses: can be simpler to use in analysis than column GLUCOSE
BA(53); submission_time_string; description: another format for the submission time, MM/(D)D/YY; example: 10/5/19; uses: analysis of submission time
BB(54); selected_sentence; description: text of the sentence that the HIT was about.; example: The school football game was last weekend.; uses: analysis of the text of particular sentences (e.g., relative to the containing story)